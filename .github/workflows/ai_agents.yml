name: AI Agents Pipeline

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [main]

permissions:
  contents: read
  pull-requests: write

jobs:
  run-ai-agents:
    runs-on: ubuntu-latest

    # We'll use static values directly in the scripts
    env:
      GITHUB_REPO: ${{ github.repository }}
      PR_NUMBER: ${{ github.event.pull_request.number }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python 3.13.0
        uses: actions/setup-python@v4
        with:
          python-version: 3.13.0

      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Build Predictor Agent
        run: |
          python -c "
          from agents.analysis.build_predictor_agent import BuildPredictorAgent, BuildPredictorConfig

          # Static configuration for testing
          agent = BuildPredictorAgent(BuildPredictorConfig(
              model='llama3-8b-8192',
              groq_api_endpoint='https://api.groq.com/openai/v1/chat/completions',
              groq_api_key='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'
          ))

          result = agent.predict_build_failure({'pr_number': '${{ github.event.pull_request.number }}'})
          print(result)
          "

      - name: Run Code Review Agent
        run: |
          python -c "
          from agents.ci_cd.code_review_agent import CodeReviewAgent, CodeReviewConfig
          import os

          # Static configuration for testing
          agent = CodeReviewAgent(CodeReviewConfig(
              model='llama3-8b-8192',
              groq_api_endpoint='https://api.groq.com/openai/v1/chat/completions',
              groq_api_key='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',
              github_token='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',
              repo_name=os.environ['GITHUB_REPO'],
              pull_request_number=int(os.environ['PR_NUMBER'])
          ))

          agent.run()
          "

      - name: Run Chat Agent
        run: |
          python -c "
          from agents.chat_agent import ChatAgent, ChatAgentConfig
          import os

          # Static configuration for testing
          agent = ChatAgent(ChatAgentConfig(
              chat_model_id='llama3-8b-8192',
              groq_api_endpoint='https://api.groq.com/openai/v1/chat/completions',
              groq_api_key='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',
              github_token='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',
              repo_name=os.environ['GITHUB_REPO'],
              pull_request_number=int(os.environ['PR_NUMBER'])
          ))

          agent.run()
          "
